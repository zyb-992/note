# 基础入门

> [java - 全网最通俗易懂的Kafka入门！_个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000021192178)

## 第一章 初始Kafka

### Kafka扮演的三大角色

- 消息系统：具备系统解耦，冗余存储，流量削峰，缓冲，异步通信，可恢复性等功能
- 存储系统：将消息持久化到磁盘中，有效地降低了数据丢失的风险，得益于Kafka的消息持久化功能和多副本机制
- 流式处理平台

### Kafka的特点

- 高可用
  - Kafka为分区引入了多副本机制，同一分区的不同副本中保存的是相同的消息（在同一个时刻，副本之间并非完全一样），副本之间也是**一主多从**的关系，leader副本负责处理读写请求，follower副本只负责从leader副本中重新选举新的leader副本对外提供服务，保证了Kafka集群中某个broker失败时仍然能保证服务可用
  - 消费者端也具备一定的容灾能力，当使用Pull模式从服务端拉取消息，并且保存了消费的具体位置(offset)，当消费者宕机恢复后重新上线或者有新的消费者上线时，可以根据在Kafka之前保存的该消费者的消费位置（__cons_）重新拉取需要的消息进行消费，这样就不会造成消息丢失

### 基本概念

1. Kafka的体系架构

   - **Producer**：生产者，发送消息的一方
   - **Consumer**：消费者，消费者连接到Kafka上并接收消息，进行相应的业务逻辑处理
   - **Broker**：服务代理节点，Broker对于Kafka来说可以简单地看作一个独立的Kafka服务节点或者Kafka服务实例
   - **Topic**：主题，逻辑上的概念，一个`Broker`可以有多个Topic，同时一个Topic中可以有多个分区`Partition`，**同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志文件**
   - **Partition**：分区，同一主题下的不同分区包含的消息是不同的，生产者可以指定将消息发送至主题的某个分区中，消息在被追加到分区日志文件中的时候都会分配一个特定偏移量`offset`，Kafka通过它来保证消息在分区内的顺序性（对于分区和消费者来说，两者都有各自的`offset`）
     - 分区的`offset`
     - 消费者的`offset`


   ![](C:\Users\zyb\AppData\Roaming\Typora\typora-user-images\image-20221031151439299.png)

2. 分区与副本（一些专业术语缩写

   1. 分区中所有副本称为AR

   2. 所有与leader副本保持一定程度同步的副本(包括leader副本在内)组成ISR，ISR集合是AR集合中的一个子集

   3. 与leader副本同步滞后过多的副本组成OSR，且AR=ISR+OSR

   4. 正常情况下，AR=ISR，OSR为空

   5. leader副本负责维护和跟踪ISR集合中所有follower副本的滞后状态

      1. 当follower副本落后太多或失效，leader副本会把它从ISR集合中删除
      2. 若OSR集合中有副本追上了leader副本，即重新同步一致了，那么leader副本回把它从OSR集合转移至ISR集合

   6. 当leader副本发生故障时，重新选举出的leader副本只会从ISR中进行挑选，而在OSR中的副本则没有资格

   7. HW和LEO

      1. `HW`：俗称高水位，标识了一个特定的消息偏移量，**消费者在主从模式下只能拉取到这个offset之前的消息**

      2. `LEO`：标识当前日志文件中下一条待写入消息的offset

      3. 例如当前分区的LEO=9，表示下一条写入消息的位置应该在9这一位置，而HW为6表示当前只能够读0-5的消息，为什么HW!=9？是因为某个从服务器在同步时还未同步到9，最大只同步到了5，因此为了避免主服务器宕机时，选举出来的新的主服务器同步的消息，会造成消费者要读取6-8的消息时，新的主服务器只同步到5，所以规定HW为这一概念

         ![](C:\Users\zyb\AppData\Roaming\Typora\typora-user-images\image-20221031153302056.png)

## 第二章 生产者

### 客户端开发

- 正常生产逻辑
  - 配置生产者客户端参数及创建相应的生产者实例
  - 构建待发送的消息
  - 发送消息
  - 关闭生产者实例



### 整体架构

- 生产者客户端由两个线程协调运行，分别为主线程和Sender线程

![](C:\Users\zyb\AppData\Roaming\Typora\typora-user-images\image-20221031161021856.png)

- 消息发送方式 序列化器 分区器 拦截器

## 第三章 消费者

### 消费者与消费组

1. 消费者负责订阅Kafka中的主题，并且从订阅的主题上拉取消息
2. 每个消费者都有一个对应的消费组，当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者
3. 两种消息投递模式
   - **点对点（P2P）模式**：基于队列，消息生产者发送消息到队列，消息消费者从队列中接收消息
   - **发布/订阅模式**：如何向一个内容节点发布和订阅消息，这个内容节点称为主题，主题被认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息
     - 如果所有消费者隶属于同一个消费组，就相当于点对点模式的应用，因为主题的每个分区平均分配给每个消费者
     - 如果所有消费者隶属于不同的消费组，就相当于发布/订阅模式的应用
4. 消费者并非逻辑上的概念，它是实际的应用案例

### 客户端开发

#### 正常消费的逻辑

- 配置消费者客户端参数以及创建相应的消费者实例
- 订阅主题
- 拉取消息并消费
- 提交消费位移
- 关闭消费者实例

#### 消息消费

1. Kafka中的消费是基于拉模式，消息消费是一个不断轮询的过程，消费者要做的是重复调用`poll()`方法
2. 消息消费有两种模式
   - **推模式**：服务端主动将消息推送给消费者
   - **拉模式**：消费者主动向服务器发起请求来拉去消息

3. poll返回值是一次拉取操作所获得的消息集合，包含了若干消息
4. 每次调用poll方法时返回的是还没有被消费国的消息集

#### 位移提交

1. 消费者的`offset`：消费者在分区中消费到的某个消息的位置，每个消费者都有自己的offset

2. 消息的`offset`：分区中每条消息都有唯一的offset，用来表示消息在分区中对应的位置

3. 消费者的消费位移`offset`存储在Kafka内部的主题(**`__consumer_offsets`**)中 这里把消费位移存储起来(持久化)的动作称为”提交“，**消费者在消费完消息之后需要执行消费位移的提交**

4. 例如当前消费者已经消费了x位置的消息，那么我们就可以说消费者的消费位移为x，此时消费者需要提交的消费位移应该为x+1而不是x，即position的位置，它表示下一条需要拉取的消息的位置

   ![](C:\Users\zyb\AppData\Roaming\Typora\typora-user-images\image-20221031173208606.png)

##### 重复消费/消息丢失

- 位移提交的具体时机不同，有可能会造成重复消费和消息丢失的现象

- **重复消费**：消费者消费了已经消费过的消息
- **消息丢失**：消费者没有按序消费分区中的消息 而是忽略/跳过了一些
- 例如 消费者poll操作拉取到消息集合为[x+2, x+7]，在消费到x+5时出现了异常，如果拉取到消息之后就进行了位移提交，即提交了x+8，那么故障恢复后，重新拉取的消息是从x+8开始的，也就是说[x+5,x+7]的消息没被消费，发生了消息丢失现象 或者 位移提交的动作是在消费完所有拉渠道的消息之后才执行的，那么当消费到x+5的时候遇到了异常，在故障恢复后，重新拉取的消息是从x+2开始的，也就是说[x+2,x+4]的消息又重新消费了一遍

![](C:\Users\zyb\AppData\Roaming\Typora\typora-user-images\image-20221031173607830.png)

5. Kafka中默认消费位移的提交方式是**自动定期提交**
   - 由消费者客户端参数enable.auto.commit配置，默认为true
   - 定期时间由客户端参数auto.commit.interval.ms配置，默认为5s
6. 自动定期提交造成的重复消费和消息丢失
   - 重复消费：假设刚提交完一次消费位移，重新poll拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者崩溃了，重启后又得从上次位移提交的地方重新开始消费
   - 消息丢失：在消息还没消费完毕时且定期提交到时的时候，又重新拉取了一批消息，此时消费者客户端崩溃，重启后，从最新拉取到的位移提交开始读取信息，而前面的消息还未被消费，造成消息丢失
7. **开启手动提交**（手动提交消费位移
   - 消费者客户端参数enable.auto.commit设置为false
   - 同步提交：对拉取到的消息先做相应的逻辑处理，然后对整个消息集做同步提交
   - 异步提交：执行的时候消费者线程不会被阻塞，在提交消费位移的结果还未返回之前就开始了新一次的拉取操作